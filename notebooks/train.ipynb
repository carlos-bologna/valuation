{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Revenue Prediction Model\n",
    "\n",
    "This model predic the revenue of the next quarter of all B3 listed companies.\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_FOLDER = \"/workspaces/valuation/data/staging/numpy\"\n",
    "TENSORBOARD_LOG_DIR = f\"/workspaces/valuation/data/staging/tensorboard/{datetime.now().strftime('%Y-%m-%d (%H:%Mh)')}\"\n",
    "\n",
    "# device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(DATA_SOURCE_FOLDER, 'X_train.npy'))\n",
    "y_train = np.load(os.path.join(DATA_SOURCE_FOLDER, 'y_train.npy'))\n",
    "X_test = np.load(os.path.join(DATA_SOURCE_FOLDER, 'X_test.npy'))\n",
    "y_test = np.load(os.path.join(DATA_SOURCE_FOLDER, 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X_train.shape[2]\n",
    "OUTPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 1000\n",
    "NUM_LAYERS = 2\n",
    "LEARNING_RATE = 0.00001\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_TRAIN_DATA = False\n",
    "SHUFFLE_TEST_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler\n",
    "X_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test data\n",
    "X_train_scaled = X_scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.from_numpy(X_train_scaled)\n",
    "y_train_torch = torch.from_numpy(y_train_scaled)\n",
    "X_test_torch = torch.from_numpy(X_test_scaled)\n",
    "y_test_torch = torch.from_numpy(y_test_scaled)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_TRAIN_DATA)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_TEST_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, test_loader):\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    data = torch.tensor(data, dtype=torch.float32)\n",
    "    data = data.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)\n",
    "    return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, loss function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    avg_loss = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "    avg_test_loss = validation(model, criterion, test_loader)\n",
    "\n",
    "    # Log the losses to TensorBoard\n",
    "    writer.add_scalar('Loss/Train', avg_loss, epoch)\n",
    "    writer.add_scalar('Loss/Test', avg_test_loss, epoch)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Avg Train Loss: {avg_loss:.4f}, Avg Test Loss: {avg_test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, X_test)\n",
    "predictions = y_scaler.inverse_transform(predictions)\n",
    "actuals = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[0:100]\n",
    "actuals = actuals[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences\n",
    "differences = predictions - actuals\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual and predicted values\n",
    "plt.plot(actuals, label='Actual Values', marker='o')\n",
    "plt.plot(predictions, label='Predicted Values', marker='x')\n",
    "\n",
    "# Plot differences\n",
    "for i in range(len(predictions)):\n",
    "    plt.plot([i, i], [predictions[i], actuals[i]], color='red', linestyle='--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Predictions vs Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
