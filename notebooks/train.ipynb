{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Revenue Prediction Model\n",
    "\n",
    "This model predic the revenue of the next quarter of all B3 listed companies.\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_FOLDER = \"/workspaces/valuation/data/staging/numpy\"\n",
    "TENSORBOARD_LOG_DIR = \"/workspaces/valuation/data/staging/tensorboard\"\n",
    "\n",
    "# device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(DATA_SOURCE_FOLDER, 'X_train.npy'))\n",
    "y_train = np.load(os.path.join(DATA_SOURCE_FOLDER, 'y_train.npy'))\n",
    "X_test = np.load(os.path.join(DATA_SOURCE_FOLDER, 'X_test.npy'))\n",
    "y_test = np.load(os.path.join(DATA_SOURCE_FOLDER, 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X_train.shape[2]\n",
    "OUTPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "LEARNING_RATE = 1.9\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 10\n",
    "SHUFFLE_TRAIN_DATA = False\n",
    "SHUFFLE_TEST_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.from_numpy(X_train)\n",
    "y_train_torch = torch.from_numpy(y_train)\n",
    "X_test_torch = torch.from_numpy(X_test)\n",
    "y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_TRAIN_DATA)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_TEST_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, test_loader):\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, loss function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Avg Train Loss: 395823337363860.4375, Avg Test Loss: 757636355193600.0000\n",
      "Epoch [2/20], Avg Train Loss: 395488356760247.3750, Avg Test Loss: 757250093628648.7500\n",
      "Epoch [3/20], Avg Train Loss: 395221041404313.6875, Avg Test Loss: 756877034360226.8750\n",
      "Epoch [4/20], Avg Train Loss: 394961671459639.3750, Avg Test Loss: 756509959471895.2500\n",
      "Epoch [5/20], Avg Train Loss: 394706461028903.0000, Avg Test Loss: 756146595677882.1250\n",
      "Epoch [6/20], Avg Train Loss: 394454206102159.9375, Avg Test Loss: 755786062887144.7500\n",
      "Epoch [7/20], Avg Train Loss: 394204375575313.1250, Avg Test Loss: 755427844729530.1250\n",
      "Epoch [8/20], Avg Train Loss: 393956646532031.6250, Avg Test Loss: 755071755956642.8750\n",
      "Epoch [9/20], Avg Train Loss: 393710932178306.4375, Avg Test Loss: 754717591005742.5000\n",
      "Epoch [10/20], Avg Train Loss: 393467055464805.1250, Avg Test Loss: 754365346862405.8750\n",
      "Epoch [11/20], Avg Train Loss: 393225119783467.1250, Avg Test Loss: 754014971432029.1250\n",
      "Epoch [12/20], Avg Train Loss: 392984972066040.9375, Avg Test Loss: 753666451909259.6250\n",
      "Epoch [13/20], Avg Train Loss: 392746666946013.8750, Avg Test Loss: 753319675808209.5000\n",
      "Epoch [14/20], Avg Train Loss: 392510166796025.4375, Avg Test Loss: 752974755502266.1250\n",
      "Epoch [15/20], Avg Train Loss: 392275501037086.6250, Avg Test Loss: 752631549364642.8750\n",
      "Epoch [16/20], Avg Train Loss: 392042615444855.7500, Avg Test Loss: 752290283750074.1250\n",
      "Epoch [17/20], Avg Train Loss: 391811542854947.1875, Avg Test Loss: 751950723183360.0000\n",
      "Epoch [18/20], Avg Train Loss: 391582266083806.5625, Avg Test Loss: 751612951670888.7500\n",
      "Epoch [19/20], Avg Train Loss: 391354843089353.6875, Avg Test Loss: 751277050611441.5000\n",
      "Epoch [20/20], Avg Train Loss: 391129153611363.0000, Avg Test Loss: 750942839509187.6250\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    avg_loss = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "    avg_test_loss = validation(model, criterion, test_loader)\n",
    "\n",
    "    # Log the losses to TensorBoard\n",
    "    writer.add_scalar('Loss/Train', avg_loss, epoch)\n",
    "    writer.add_scalar('Loss/Test', avg_test_loss, epoch)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Avg Train Loss: {avg_loss:.4f}, Avg Test Loss: {avg_test_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
