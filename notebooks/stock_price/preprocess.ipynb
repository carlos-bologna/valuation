{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_FOLDER = \"/workspaces/valuation/data/staging/stocks\"\n",
    "DATA_DESTINATION_FOLDER = \"/workspaces/valuation/data\"\n",
    "\n",
    "SOURCE_PATH = \"historical_prices.csv\"\n",
    "DESTINATION_PATH = \"stock_prices.duckdb\"\n",
    "\n",
    "TICKER = \"VALE5.SA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_path = os.path.join(DATA_SOURCE_FOLDER, OUTPUT_FILENAME)\n",
    "\n",
    "# Create or connect to the DuckDB database\n",
    "conn = duckdb.connect(database=db_path, read_only=False)\n",
    "\n",
    "# Read data\n",
    "df = conn.sql(f\"SELECT * FROM {SOURCE_TABLE}\").fetchdf()\n",
    "\n",
    "# Close the DuckDB connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Nulls\n",
    "\n",
    "Remove rows with at least one null value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProfileReport(df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DIA_REFER\"] = df[\"DT_REFER\"].dt.day\n",
    "df[\"MES_REFER\"] = df[\"DT_REFER\"].dt.month   \n",
    "df[\"ANO_REFER\"] = df[\"DT_REFER\"].dt.year\n",
    "\n",
    "# List of parameter, target must be the first one.\n",
    "FEATURE_NAMES = ['RECEITA', 'EBIT', 'LAIR', 'PERIODO_MESES', 'DIA_REFER', 'MES_REFER', 'ANO_REFER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the time steps (lookback)\n",
    "\n",
    "The shape must be:\n",
    "(samples, time steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date if necessary\n",
    "df.sort_values(by=['CD_CVM', 'DT_REFER'], inplace=True)\n",
    "\n",
    "# Create sequences for each CD_CVM group\n",
    "grouped = df.groupby('CD_CVM')\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []\n",
    "\n",
    "for name, group in grouped:\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "        \n",
    "    # Select the necessary columns\n",
    "    data = group[FEATURE_NAMES].values\n",
    "        \n",
    "    # Create the sequences\n",
    "    for i in range(TIME_STEPS, len(data)):\n",
    "        X_list.append(data[i-TIME_STEPS:i])\n",
    "        y_list.append(data[i, 0])\n",
    "\n",
    "    # Split into train and test\n",
    "    split_index = len(X_list) - TEST_SIZE\n",
    "    X_train_list.extend(X_list[:split_index])\n",
    "    y_train_list.extend(y_list[:split_index])\n",
    "    X_test_list.extend(X_list[split_index:])\n",
    "    y_test_list.extend(y_list[split_index:])\n",
    "    \n",
    "# Convert lists to numpy arrays\n",
    "X_train, y_train = np.array(X_train_list, dtype=np.float32), np.array(y_train_list, dtype=np.float32)\n",
    "X_test, y_test = np.array(X_test_list, dtype=np.float32), np.array(y_test_list, dtype=np.float32)\n",
    "\n",
    "# Reshape the targets from (n,) to (n,1)\n",
    "y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "y_test = np.reshape(y_test, (len(y_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler\n",
    "#scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test data\n",
    "#X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "#X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save numpy arrays to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (9511, 3, 7)\n",
      "X_test_scaled shape: (1060, 3, 7)\n",
      "y_train shape: (9511, 1)\n",
      "y_test shape: (1060, 1)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(NUMPY_DATA_DESTINATION):\n",
    "    os.makedirs(NUMPY_DATA_DESTINATION)\n",
    "    \n",
    "np.save(os.path.join(NUMPY_DATA_DESTINATION, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(NUMPY_DATA_DESTINATION, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(NUMPY_DATA_DESTINATION, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(NUMPY_DATA_DESTINATION, 'y_test.npy'), y_test)\n",
    "\n",
    "# Print shapes to verify the split and scaling\n",
    "print(\"X_train_scaled shape:\", X_train.shape)\n",
    "print(\"X_test_scaled shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
